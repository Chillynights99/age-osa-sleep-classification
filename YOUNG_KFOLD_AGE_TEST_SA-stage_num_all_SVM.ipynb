{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat, savemat\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_num=39\n",
    "a = []\n",
    "\n",
    "for i in range(10):\n",
    "    a.append(np.ceil((np.random.permutation(p_num)+1)/(p_num/5.0)).reshape(1,p_num))\n",
    "\n",
    "a = np.array(a)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd28ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal_Y=np.array([29,35,45,55,65,83,90,104,106,108,110,112,126,137,140,151,154,163]);\n",
    "#normal_M=np.array([15,26,42,44,53,64,89,105,160,161]);\n",
    "#normal_O=np.array([1,10,12,13,14,18,20,41,62,77,133,153]);\n",
    " \n",
    "#mtom_Y=np.array([25,47,50,56,59,63,92,111,51,58,80,94,102,114,144]);\n",
    "#mtom_M=np.array([5,93,99,116,122,130,143,3,8,11,38,49,54,68,72,82,88,91,95,98,107,138]);\n",
    "#mtom_O=np.array([2,4,6,7,16,96,100,118,125,142,145,21,67,101,103,115,121,127,136]);\n",
    " \n",
    "#severe_Y=np.array([24,28,31,34,36,40,60,76,128,135]);\n",
    "#severe_M=np.array([17,19,23,27,57,66,71,74,78,79,84,85,109,139,152]);\n",
    "#severe_O=np.array([30,43,46,48,52,69,70,73,75,81,86,97,117,129,131,134,156,162]);\n",
    "\n",
    "normal_Y=np.array([35,45,55,65,83,104,106,108,110,112,126,137,151,154,163]);\n",
    "normal_M=np.array([15,26,42,44,53,64,89,105,160,161]);\n",
    "normal_O=np.array([1,10,12,13,14,18,20,41,62,77,133,153]);\n",
    " \n",
    "mtom_Y=np.array([25,47,50,56,59,63,92,111,51,58,94,102,114,144]);\n",
    "mtom_M=np.array([5,99,116,122,130,8,11,38,49,68,82,91,95,98,138]);\n",
    "mtom_O=np.array([2,4,7,96,118,125,142,21,67,101,115,127,136]);\n",
    " \n",
    "severe_Y=np.array([24,28,31,34,36,40,60,76,128,135]);\n",
    "severe_M=np.array([17,19,23,57,66,71,74,78,79,84,85,109,139,152]);\n",
    "severe_O=np.array([30,43,46,69,70,73,75,86,97,117,129,131,134,156,162]);\n",
    "\n",
    "\n",
    "control_num=np.array([35,45,55,65,83,104,106,108,110,112,126,137,151,154,163,\n",
    "                      25,47,50,56,59,63,92,111,51,58,94,102,114,144,\n",
    "                      24,28,31,34,36,40,60,76,128,135]);\n",
    "Mid=np.array([15,26,42,44,53,64,89,105,160,161,\n",
    "              5,99,116,122,130,8,11,38,49,68,82,91,95,98,138,\n",
    "              17,19,23,57,66,71,74,78,79,84,85,109,139,152]);\n",
    "Old=np.array([1,10,12,13,14,18,20,41,62,77,133,153,\n",
    "              2,4,7,96,118,125,142,21,67,101,115,127,136,\n",
    "              30,43,46,69,70,73,75,86,97,117,129,131,134,156,162]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ca1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "for k in range(len(a)):\n",
    "    b = a[k]\n",
    "    \n",
    "    for m in range(1,6):\n",
    "        index_test = np.where(b == m)\n",
    "        index_train = np.where(b != m)\n",
    "        \n",
    "        test_set = np.empty((32,0))\n",
    "        train_set = np.empty((32,0))\n",
    "        test_set_label = np.empty((1,0))\n",
    "        train_set_label = np.empty((1,0))\n",
    "        \n",
    "        test_set_M = np.empty((32,0))\n",
    "        test_set_label_M = np.empty((1,0))\n",
    "        test_set_O = np.empty((32,0))\n",
    "        test_set_label_O= np.empty((1,0))\n",
    "                \n",
    "        train_set2 = np.empty((32,0))\n",
    "        test_set_label2 = np.empty((1,0))\n",
    "        \n",
    "        test = index_test[1]\n",
    "        train = index_train[1]\n",
    "        \n",
    "        print(\"{}번째 아우터 루프의 {}번째 테스트 인덱스\".format(k, m))\n",
    "        print(test)\n",
    "        print(\"{}번째 아우터 루프의 {}번째 트레인 인덱스 \".format(k, m))\n",
    "        print(train)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        for n in test:\n",
    "            test_data = loadmat(\"/user/chae2089/CWpaper/features_6/subject{}_PSD_TOTAL.mat\".format(control_num[n]))\n",
    "            test_data = test_data['TOTAL']\n",
    "            test_set = np.append(test_set, test_data, 1)\n",
    "            \n",
    "            test_label = loadmat(\"/user/chae2089/CWpaper/features_6/subject{}_PSD_TOTAL_label.mat\".format(control_num[n]))\n",
    "            test_label = test_label['label_TOTAL']\n",
    "            test_set_label = np.append(test_set_label, test_label, 1)\n",
    "            \n",
    "        for m in train:\n",
    "            train_data = loadmat(\"/user/chae2089/CWpaper/features_6/subject{}_PSD_TOTAL.mat\".format(control_num[m]))\n",
    "            train_data = train_data['TOTAL']\n",
    "            train_set = np.append(train_set, train_data, 1)\n",
    "            \n",
    "            train_label = loadmat(\"/user/chae2089/CWpaper/features_6/subject{}_PSD_TOTAL_label.mat\".format(control_num[m]))\n",
    "            train_label = train_label['label_TOTAL']\n",
    "            train_set_label = np.append(train_set_label, train_label, 1)\n",
    "            \n",
    "        \n",
    "        ind1=np.where(train_set_label==1)\n",
    "        ind2=np.where(train_set_label==2)\n",
    "        ind3=np.where(train_set_label==3)\n",
    "        ind4=np.where(train_set_label==4)\n",
    "        ind5=np.where(train_set_label==5)\n",
    "        print([np.size(ind1[1]),np.size(ind2[1]),np.size(ind3[1]),np.size(ind4[1]),np.size(ind5[1])])\n",
    "        st_min=np.min([np.size(ind1[1]),np.size(ind2[1]),np.size(ind3[1]),np.size(ind5[1])])\n",
    "        ##st_num=np.where([np.size(ind1[1]),np.size(ind2[1]),np.size(ind3[1]),np.size(ind5[1])]==st_min)[0]\n",
    "        ##print(st_num+1)\n",
    "\n",
    "        st1=list(range(np.size(ind1[1]))); st1_pos=random.sample(st1,st_min); st1_p=ind1[1][st1_pos]\n",
    "        st2=list(range(np.size(ind2[1]))); st2_pos=random.sample(st2,st_min); st2_p=ind2[1][st2_pos]\n",
    "        st3=list(range(np.size(ind3[1]))); st3_pos=random.sample(st3,st_min); st3_p=ind3[1][st3_pos]\n",
    "        st4_p=ind4[1]\n",
    "        st5=list(range(np.size(ind5[1]))); st5_pos=random.sample(st5,st_min); st5_p=ind5[1][st5_pos]\n",
    "\n",
    "        train_set2 = np.hstack((train_set[:,st1_p],train_set[:,st2_p],train_set[:,st3_p],train_set[:,st4_p],train_set[:,st5_p]))\n",
    "        train_set_label2 = np.hstack((train_set_label[:,st1_p],train_set_label[:,st2_p],train_set_label[:,st3_p],train_set_label[:,st4_p],train_set_label[:,st5_p]))    \n",
    "\n",
    "        train_set2 = np.transpose(train_set2)\n",
    "        train_set_label2 = np.transpose(train_set_label2).ravel()\n",
    "    \n",
    "        test_set = np.transpose(test_set)\n",
    "        test_set_label = np.transpose(test_set_label)\n",
    "        \n",
    "        param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001, 10]}\n",
    "        clf_grid = GridSearchCV(SVC(kernel = 'rbf'), param_grid) \n",
    "        clf_grid.fit(train_set2, train_set_label2)\n",
    "        C_best = clf_grid.best_params_[\"C\"]\n",
    "        gamma_best = clf_grid.best_params_[\"gamma\"]\n",
    "\n",
    "        model = SVC(kernel = 'rbf', C=C_best, gamma=gamma_best)\n",
    "        model.fit(train_set2, train_set_label2)\n",
    "        \n",
    "        pred = model.predict(test_set)\n",
    "        \n",
    "        ##### M #########\n",
    "        c = random.sample(range(len(normal_M)), len(test))\n",
    "                \n",
    "        for n in Mid[c]:\n",
    "            test_data_M = loadmat(\"/user/chae2089/CWpaper/features_6/subject{}_PSD_TOTAL.mat\".format(n))\n",
    "            test_data_M = test_data_M['TOTAL']\n",
    "            test_set_M = np.append(test_set_M, test_data_M, 1)\n",
    "            \n",
    "            test_label_M = loadmat(\"/user/chae2089/CWpaper/features_6/subject{}_PSD_TOTAL_label.mat\".format(n))\n",
    "            test_label_M = test_label_M['label_TOTAL']\n",
    "            test_set_label_M = np.append(test_set_label_M, test_label_M, 1)\n",
    "        \n",
    "            \n",
    "        test_set_M = np.transpose(test_set_M)\n",
    "        test_set_label_M = np.transpose(test_set_label_M)\n",
    "        pred_M = model.predict(test_set_M)\n",
    "        \n",
    "        ##### O #########\n",
    "        c_1 = random.sample(range(len(normal_O)), len(test))\n",
    "                \n",
    "        for n in Old[c_1]:\n",
    "            test_data_O = loadmat(\"/user/chae2089/CWpaper/features_6/subject{}_PSD_TOTAL.mat\".format(n))\n",
    "            test_data_O = test_data_O['TOTAL']\n",
    "            test_set_O = np.append(test_set_O, test_data_O, 1)\n",
    "            \n",
    "            test_label_O = loadmat(\"/user/chae2089/CWpaper/features_6/subject{}_PSD_TOTAL_label.mat\".format(n))\n",
    "            test_label_O = test_label_O['label_TOTAL']\n",
    "            test_set_label_O = np.append(test_set_label_O, test_label_O, 1)\n",
    "        \n",
    "        test_set_O = np.transpose(test_set_O)\n",
    "        test_set_label_O = np.transpose(test_set_label_O)\n",
    "        pred_O = model.predict(test_set_O)\n",
    "        \n",
    "        \n",
    "        ######### SAVE normal_Y\n",
    "        result=confusion_matrix(test_set_label,pred)\n",
    "\n",
    "        filename=(\"/user/chae2089/CWpaper/young_kfold_feature6/num_118/young/result_%d\" %(num))\n",
    "        np.savetxt(filename, result)\n",
    "        \n",
    "        report = classification_report(test_set_label, pred)\n",
    "        report2=report.split()\n",
    "        with open(\"/user/chae2089/CWpaper/young_kfold_feature6/num_118/young/report_{}.csv\".format(num), 'w') as fp:\n",
    "            for item in report2:\n",
    "                fp.write(\"%s\\n\" % item)\n",
    "                \n",
    "        ######### SAVE normal_M    \n",
    "        result_M=confusion_matrix(test_set_label_M,pred_M)\n",
    "\n",
    "        filename=(\"/user/chae2089/CWpaper/young_kfold_feature6/num_118/mid/result_%d\" %(num))\n",
    "        np.savetxt(filename, result_M)\n",
    "        \n",
    "        report_M = classification_report(test_set_label_M, pred_M)\n",
    "        report2_M=report_M.split()\n",
    "        with open(\"/user/chae2089/CWpaper/young_kfold_feature6/num_118/mid/report_{}.csv\".format(num), 'w') as fp:\n",
    "            for item in report2_M:\n",
    "                fp.write(\"%s\\n\" % item)\n",
    "            \n",
    "        ######### SAVE normal_O    \n",
    "        result_O=confusion_matrix(test_set_label_O,pred_O)\n",
    "\n",
    "        filename=(\"/user/chae2089/CWpaper/young_kfold_feature6/num_118/old/result_%d\" %(num))\n",
    "        np.savetxt(filename, result_O)\n",
    "        \n",
    "        report_O = classification_report(test_set_label_O, pred_O)\n",
    "        report2_O=report_O.split()\n",
    "        with open(\"/user/chae2089/CWpaper/young_kfold_feature6/num_118/old/report_{}.csv\".format(num), 'w') as fp:\n",
    "            for item in report2_O:\n",
    "                fp.write(\"%s\\n\" % item)\n",
    "                 \n",
    "                \n",
    "        num = num+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6219bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
